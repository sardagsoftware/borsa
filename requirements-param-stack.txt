# ═══════════════════════════════════════════════════════════════
# AILYDIAN PARAM STACK - PYTHON DEPENDENCIES
# TR-ağır çokdilli model + QLoRA finetune + vLLM + RAG
# ═══════════════════════════════════════════════════════════════

# ===  EĞİTİM/FİNETUNE (Training & Finetuning) ===
torch>=2.1.0  # CUDA için: pip install torch --index-url https://download.pytorch.org/whl/cu121
transformers>=4.44.0
accelerate>=0.33.0
peft>=0.12.0
bitsandbytes>=0.41.0
# flash-attn>=2.5.0  # CUDA gerekli, opsiyonel (pip install flash-attn --no-build-isolation)
deepspeed>=0.14.0  # veya PyTorch FSDP kullan

# === TOKENİZER/VERİ (Tokenizer & Data Processing) ===
sentencepiece>=0.2.0
datasets>=2.14.0
cleanlab>=2.6.0
dvc>=3.48.0
ray[data]>=2.9.0
python-dotenv>=1.0.0
tqdm>=4.66.0

# === SUNUM/INFERENCE (Inference & Serving) ===
vllm>=0.6.0
# text-generation>=0.6.0  # HF TGI client (opsiyonel)
# tritonclient[all]>=2.48.0  # NVIDIA Triton (opsiyonel)

# === RAG (Retrieval-Augmented Generation) ===
faiss-cpu>=1.8.0  # GPU için: pip install faiss-gpu
qdrant-client>=1.11.0
# pymilvus>=2.4.0  # alternatif vektör DB
sentence-transformers>=3.0.0
langchain>=0.3.0
langchain-community>=0.3.0

# === DEĞERLENDİRME/GUARDRAİL (Evaluation & Guardrails) ===
lm-eval>=0.4.0
presidio-analyzer>=2.2.0
presidio-anonymizer>=2.2.0
guardrails-ai>=0.5.0

# === MLOPS/GÖZLEMLENEBİLİRLİK (MLOps & Observability) ===
mlflow>=2.14.0
# wandb>=0.17.0  # alternatif experiment tracking
prometheus-client>=0.20.0
opentelemetry-sdk>=1.25.0
opentelemetry-instrumentation-fastapi>=0.46b0

# === ÇOK KİRACILI SİSTEM/GÜVENLİK (Multi-tenancy & Security) ===
pynacl>=1.5.0  # Ed25519 imzalama (attestation)
pydantic>=2.0.0  # Veri validasyonu
fastapi>=0.115.0  # API framework
uvicorn[standard]>=0.30.0  # ASGI server
python-multipart>=0.0.9  # Form data handling
trl>=0.11.0  # DPO training (Transformer Reinforcement Learning)
kubernetes>=30.0.0  # K8s client (KServe canary)

# === NOTLAR ===
# 1. CUDA 12.1 için PyTorch:
#    pip install torch --index-url https://download.pytorch.org/whl/cu121
#
# 2. FlashAttention (opsiyonel, performans için):
#    pip install flash-attn --no-build-isolation
#
# 3. vLLM GPU desteği:
#    CUDA 12.1+ ve PyTorch 2.1+ gerekli
#
# 4. Bu dosya PyTorch/ML bileşenleri içindir.
#    Node.js dependencies için package.json kullanın.
