# ğŸš€ PARAM STACK - SONRAKÄ° ADIMLAR (HIZLI BAÅLANGIÃ‡)

**Tarih:** 2025-10-19
**Durum:** âœ… Infrastructure hazÄ±r, ÅŸimdi RLAIF test'e geÃ§iÅŸ

---

## ğŸ“‹ ÅU ANDA NEREDEYIZ?

âœ… **Tamamlanan:**
- Multi-tenant infrastructure
- Ed25519 attestation
- Guardrails.ai security policy
- vLLM launch script (optimized)
- RLAIF preference generator script
- DPO training script
- KServe Canary deployment manifests

â³ **Åimdi yapÄ±lacak:**
- API key kurulumu
- Demo test (5 prompt ile RLAIF)
- Preference data kalite kontrolÃ¼

---

## ğŸ¯ SONRAKÄ° 5 ADIM (15 DAKÄ°KA)

### AdÄ±m 1: API Key Kurulumu (2 dakika)

```bash
# Terminal'de Ã§alÄ±ÅŸtÄ±r
./setup-api-key.sh
```

**Ne yapacak:**
- API key'ini gÃ¼venli ÅŸekilde alacak (gÃ¶rÃ¼nmez input)
- `.env` dosyasÄ±na kaydedecek (chmod 600)
- Validation yapacak

**API key nereden:**
- https://console.anthropic.com/settings/keys
- Format: `sk-ant-api03-...`

---

### AdÄ±m 2: Virtual Environment (3 dakika)

```bash
# Virtual environment oluÅŸtur
python3 -m venv venv

# Aktive et
source venv/bin/activate

# Dependencies yÃ¼kle (sadece gerekli olanlar)
pip install anthropic python-dotenv

# DoÄŸrulama
python3 -c "import anthropic; print('âœ… Anthropic SDK yÃ¼klÃ¼')"
```

---

### AdÄ±m 3: Demo Prompts OluÅŸtur (1 dakika)

```bash
# Demo prompts oluÅŸtur
python apps/rlaif/generate_preferences.py --create-demo

# Kontrol et
cat data/demo_prompts.jsonl
```

**OluÅŸturulacak prompts:**
1. "Ailydian AI Ecosystem nedir?"
2. "PyTorch ile model nasÄ±l eÄŸitilir?"
3. "TÃ¼rkÃ§e doÄŸal dil iÅŸleme iÃ§in en iyi yaklaÅŸÄ±mlar nelerdir?"
4. "COVID-19 aÅŸÄ±sÄ±nÄ±n yan etkileri nelerdir?"
5. "Anayasa Mahkemesi'ne bireysel baÅŸvuru sÃ¼reci nasÄ±l iÅŸler?"

---

### AdÄ±m 4: RLAIF Test (5 dakika - Ä°LK PROMPT)

```bash
# Sadece 1 prompt ile test (hÄ±zlÄ±)
echo '{"prompt": "Ailydian AI Ecosystem nedir?"}' > data/test_single_prompt.jsonl

# RLAIF Ã§alÄ±ÅŸtÄ±r (tek prompt, 2 response)
python apps/rlaif/generate_preferences.py \
  --prompts data/test_single_prompt.jsonl \
  --output data/test_preferences.jsonl \
  --num-responses 2

# Sonucu kontrol et
cat data/test_preferences.jsonl | python -m json.tool
```

**Beklenen Ã§Ä±ktÄ±:**
```json
{
  "prompt": "Ailydian AI Ecosystem nedir?",
  "chosen": "... (yÃ¼ksek skorlu cevap)",
  "rejected": "... (dÃ¼ÅŸÃ¼k skorlu cevap)",
  "chosen_score": 8.5,
  "rejected_score": 6.2,
  "metadata": {
    "chosen_temp": 0.5,
    "rejected_temp": 0.9,
    "num_candidates": 2
  }
}
```

---

### AdÄ±m 5: Kalite KontrolÃ¼ (4 dakika)

```bash
# Preference quality check
python3 -c "
import json

with open('data/test_preferences.jsonl', 'r') as f:
    for line in f:
        pair = json.loads(line)
        print('='*60)
        print(f'Prompt: {pair[\"prompt\"]}')
        print('')
        print(f'âœ… CHOSEN (Score: {pair[\"chosen_score\"]:.1f}):')
        print(f'   {pair[\"chosen\"][:150]}...')
        print('')
        print(f'âŒ REJECTED (Score: {pair[\"rejected_score\"]:.1f}):')
        print(f'   {pair[\"rejected\"][:150]}...')
        print('')
        print(f'Score Gap: {pair[\"chosen_score\"] - pair[\"rejected_score\"]:.1f}')
        print('='*60)
"
```

**BaÅŸarÄ± kriterleri:**
- âœ… Chosen score > Rejected score
- âœ… Score gap â‰¥ 1.5 (ideal: â‰¥ 2.0)
- âœ… Chosen yanÄ±t daha detaylÄ± ve doÄŸru
- âœ… Rejected yanÄ±t eksik veya belirsiz

---

## ğŸ‰ BAÅARILI OLURSA - SONRAKI ADIMLAR

### 1. Full Demo (10 dakika)
```bash
# TÃ¼m 5 prompt ile RLAIF
python apps/rlaif/generate_preferences.py \
  --prompts data/demo_prompts.jsonl \
  --output data/preferences.jsonl \
  --num-responses 4

# Her 10 promptta checkpoint kaydediliyor
```

### 2. Production Data Toplama (1-2 gÃ¼n)
```bash
# 100-1000 TÃ¼rkÃ§e prompt topla:
# - TÄ±p sorularÄ±
# - Hukuk sorularÄ±
# - Genel AI sorularÄ±
# - TÃ¼rkÃ§e NLP sorularÄ±
```

### 3. DPO Training (2-4 saat)
```bash
# Virtual env'de
pip install torch transformers peft trl bitsandbytes

# DPO training
python apps/trainer/dpo_train.py \
  --base_model mistralai/Mistral-7B-Instruct-v0.3 \
  --dataset data/preferences.jsonl \
  --output_dir data/artifacts/adapters/ailydian-dpo \
  --epochs 3 \
  --batch_size 4

# GPU gerekli (minimum: NVIDIA T4 16GB)
```

---

## âš ï¸ TROUBLESHOOTING

### Hata: "ModuleNotFoundError: No module named 'anthropic'"
```bash
# Virtual env aktif mi kontrol et
which python  # venv/bin/python olmalÄ±

# DeÄŸilse aktive et
source venv/bin/activate

# YÃ¼kle
pip install anthropic python-dotenv
```

### Hata: "ANTHROPIC_API_KEY not found"
```bash
# .env dosyasÄ± var mÄ±?
ls -la .env

# YÃ¼klenmiÅŸ mi?
python3 -c "from dotenv import load_dotenv; import os; load_dotenv(); print(os.getenv('ANTHROPIC_API_KEY', 'NOT FOUND'))"

# Yoksa setup-api-key.sh tekrar Ã§alÄ±ÅŸtÄ±r
./setup-api-key.sh
```

### Hata: "Rate limit exceeded"
```bash
# Anthropic API rate limit:
# - Tier 1: 50 requests/minute
# - Tier 2: 1000 requests/minute

# Ã‡Ã¶zÃ¼m: --num-responses azalt (4 â†’ 2)
# veya sleep time arttÄ±r (generate_preferences.py:171, 186)
```

### Hata: "Out of memory" (GPU)
```bash
# DPO training iÃ§in GPU gerekli
# Minimum: NVIDIA T4 16GB

# Yoksa:
# 1. Batch size azalt (--batch_size 4 â†’ 2)
# 2. Model deÄŸiÅŸtir (Mistral-7B â†’ TinyLlama-1.1B)
# 3. Google Colab kullan (Ã¼cretsiz T4)
```

---

## ğŸ“Š BEKLENEN PERFORMANS

### RLAIF (Tek Prompt)
- **SÃ¼re:** ~30 saniye
- **API calls:** 6 adet
  - 2 response generation
  - 2 scoring
  - Toplam: 4 Claude API call
- **Maliyet:** ~$0.01-0.02

### RLAIF (5 Demo Prompt)
- **SÃ¼re:** ~2-3 dakika
- **API calls:** 30 adet (5 Ã— 6)
- **Maliyet:** ~$0.05-0.10

### DPO Training (100 Preference Pairs)
- **SÃ¼re:** ~30-45 dakika (T4 GPU)
- **GPU Memory:** ~12-14GB
- **Disk:** ~2GB (model + checkpoints)

---

## ğŸ¯ BAÅARI KRÄ°TERLERÄ°

### Phase 1: RLAIF Test âœ…
- [ ] API key kuruldu
- [ ] Virtual env hazÄ±r
- [ ] Demo prompts oluÅŸturuldu
- [ ] Ä°lk preference pair Ã¼retildi
- [ ] Score gap â‰¥ 1.5

### Phase 2: Full RLAIF ğŸ”„
- [ ] 5 demo prompt tamamlandÄ±
- [ ] TÃ¼m score gaps â‰¥ 1.5
- [ ] Chosen yanÄ±tlar kaliteli
- [ ] Checkpoint kaydedildi

### Phase 3: Production Data ğŸš€
- [ ] 100+ TÃ¼rkÃ§e prompt toplandÄ±
- [ ] RLAIF ile preference pairs Ã¼retildi
- [ ] Data quality validation yapÄ±ldÄ±
- [ ] DPO training iÃ§in hazÄ±r

---

## ğŸ“ YARDIM

### DÃ¶kÃ¼manlar
- `PARAM-STACK-FINAL-COMPLETE-TR-2025-10-19.md` â†’ Full implementation guide
- `PARAM-STACK-TEST-RAPORU-TR-2025-10-19.md` â†’ Test results
- `PYTORCH-QUICK-REFERENCE-TR.md` â†’ PyTorch basics

### Scripts
- `setup-api-key.sh` â†’ API key setup
- `apps/rlaif/generate_preferences.py` â†’ RLAIF generator
- `apps/trainer/dpo_train.py` â†’ DPO training

### Example Commands
```bash
# RLAIF help
python apps/rlaif/generate_preferences.py --help

# DPO help
python apps/trainer/dpo_train.py --help
```

---

## âœ… CHECKLIST - BUGÃœN

**Hemen ÅŸimdi yapÄ±lacaklar (15 dakika):**

- [ ] `./setup-api-key.sh` Ã§alÄ±ÅŸtÄ±r â†’ API key kurulumu
- [ ] `python3 -m venv venv && source venv/bin/activate` â†’ Virtual env
- [ ] `pip install anthropic python-dotenv` â†’ Dependencies
- [ ] `python apps/rlaif/generate_preferences.py --create-demo` â†’ Demo prompts
- [ ] Ä°lk RLAIF testi â†’ 1 prompt ile preference pair Ã¼ret
- [ ] Sonucu kontrol et â†’ Score gap â‰¥ 1.5 mi?

**BaÅŸarÄ±lÄ± olursa (opsiyonel, 10 dakika):**

- [ ] Full demo â†’ 5 prompt ile RLAIF
- [ ] Kalite analizi â†’ TÃ¼m pairs iÃ§in score check

---

**ğŸ‰ BaÅŸarÄ±lar! RLAIF test'ine baÅŸlayabilirsin!**

**Ä°lk komut:**
```bash
./setup-api-key.sh
```
