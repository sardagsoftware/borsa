// üéØ SPECIALIZED AI CHAT ENDPOINT - Icon-based AI Selection
// Bu dosyayƒ± server.js'e ekleyin (satƒ±r 2573'ten sonra)

app.post('/api/chat/specialized', async (req, res) => {
  const { message, aiType, history = [], temperature = 0.7, max_tokens = 2048 } = req.body;

  if (!message) {
    return res.status(400).json({
      success: false,
      error: 'Message gerekli'
    });
  }

  try {
    let result;
    let providerUsed;

    // üéØ AI Type based intelligent routing
    switch(aiType) {
      case 'code':
        // Z.AI for code generation
        console.log('üíª Routing to Z.AI for code generation');
        if (process.env.ZAI_API_KEY || process.env.OPENAI_API_KEY) {
          result = await callOpenAIAPI(message, history, 0.2, max_tokens);
          providerUsed = 'Z.AI (OpenAI Codex)';
        } else if (process.env.GROQ_API_KEY) {
          result = await callGroqAPI(message, history, 0.3, max_tokens, 'llama-3.3-70b-versatile');
          providerUsed = 'Groq (Code Mode)';
        } else {
          result = await callGoogleGeminiAPI(message, history, 0.2, max_tokens);
          providerUsed = 'Gemini (Code Mode)';
        }
        break;

      case 'reasoning':
        // DeepSeek R1 for deep reasoning
        console.log('üß† Routing to DeepSeek R1 for deep reasoning');
        if (process.env.DEEPSEEK_API_KEY) {
          try {
            const deepseekResponse = await fetch('https://api.deepseek.com/v1/chat/completions', {
              method: 'POST',
              headers: {
                'Authorization': `Bearer ${process.env.DEEPSEEK_API_KEY}`,
                'Content-Type': 'application/json'
              },
              body: JSON.stringify({
                model: 'deepseek-reasoner',
                messages: [
                  {
                    role: 'system',
                    content: 'You are DeepSeek R1, an advanced reasoning AI. Think step-by-step and provide detailed explanations.'
                  },
                  ...history.map(h => ({ role: h.role, content: h.content })),
                  {
                    role: 'user',
                    content: message
                  }
                ],
                temperature: 0.5,
                max_tokens: max_tokens
              })
            });

            if (!deepseekResponse.ok) {
              throw new Error(`DeepSeek API error: ${deepseekResponse.status}`);
            }

            const deepseekData = await deepseekResponse.json();
            result = {
              response: deepseekData.choices[0].message.content,
              usage: deepseekData.usage || { prompt_tokens: 0, completion_tokens: 0, total_tokens: 0 }
            };
            providerUsed = 'DeepSeek R1 (Advanced Reasoning)';
          } catch (error) {
            console.error('‚ùå DeepSeek R1 Error:', error);
            // Fallback to Anthropic Claude
            if (process.env.ANTHROPIC_API_KEY) {
              result = await callAnthropicAPI(message, history, 0.5, max_tokens);
              providerUsed = 'Claude (Reasoning Fallback)';
            } else {
              result = await callGroqAPI(message, history, 0.5, max_tokens, 'llama-3.3-70b-versatile');
              providerUsed = 'Groq (Reasoning Mode)';
            }
          }
        } else if (process.env.ZHIPU_API_KEY) {
          result = await callZhipuAPI(message, history, 0.5, max_tokens, 'glm-4');
          providerUsed = 'Zhipu GLM-4 (Deep Reasoning)';
        } else if (process.env.ANTHROPIC_API_KEY) {
          result = await callAnthropicAPI(message, history, 0.5, max_tokens);
          providerUsed = 'Claude (Reasoning Mode)';
        } else {
          result = await callGroqAPI(message, history, 0.5, max_tokens, 'llama-3.3-70b-versatile');
          providerUsed = 'Groq (Reasoning Mode)';
        }
        break;

      case 'video':
        // Azure Video Indexer / Video Analysis
        console.log('üé• Routing to Video Analysis AI');
        if (process.env.AZURE_VIDEO_INDEXER_KEY || process.env.AZURE_OPENAI_API_KEY) {
          // Use GPT-4 Vision or specialized model for video understanding
          const videoAnalysisPrompt = `[Video Analysis Mode] ${message}

üé• **Video AI Yardƒ±mcƒ±**

Video ile ilgili sorunuza yardƒ±mcƒ± olabilirim:
- Video y√ºkleme ve analiz
- Video i√ßeriƒüi anlama
- Otomatik altyazƒ± olu≈üturma
- Sahne tespiti
- Nesne ve y√ºz tanƒ±ma

**Not:** Video dosyasƒ±nƒ± y√ºklemek i√ßin video ikonu √ºzerindeki y√ºkleme √∂zelliƒüini kullanƒ±n.`;

          result = await callGroqAPI(videoAnalysisPrompt, history, 0.3, max_tokens, 'llama-3.3-70b-versatile');
          result.response = videoAnalysisPrompt;
          providerUsed = 'Video Analysis AI';
        } else {
          const videoPrompt = `üé• Video yardƒ±mcƒ± modu aktif.\n\n"${message}"\n\nVideo y√ºkleme, analiz ve soru-cevap i√ßin hazƒ±rƒ±m!`;
          result = {
            response: videoPrompt,
            usage: { prompt_tokens: 30, completion_tokens: 60, total_tokens: 90 }
          };
          providerUsed = 'Video Assistant';
        }
        break;

      case 'general':
        // Groq for ultra-fast general queries
        console.log('‚ö° Routing to Groq for speed');
        if (process.env.GROQ_API_KEY) {
          result = await callGroqAPI(message, history, temperature, max_tokens, 'llama-3.3-70b-versatile');
          providerUsed = 'Groq Llama 3.3 70B (Ultra-Fast)';
        } else if (process.env.GOOGLE_AI_API_KEY) {
          result = await callGoogleGeminiAPI(message, history, temperature, max_tokens);
          providerUsed = 'Google Gemini (Fast Mode)';
        } else {
          result = await callOpenAIAPI(message, history, temperature, max_tokens);
          providerUsed = 'OpenAI (General)';
        }
        break;

      case 'image':
        // Azure DALL-E 3 for image generation
        console.log('üé® Routing to Azure DALL-E 3 for image generation');
        if (process.env.AZURE_OPENAI_API_KEY && process.env.AZURE_OPENAI_ENDPOINT) {
          try {
            const imageResponse = await fetch(`${process.env.AZURE_OPENAI_ENDPOINT}/openai/deployments/dall-e-3/images/generations?api-version=2024-02-01`, {
              method: 'POST',
              headers: {
                'api-key': process.env.AZURE_OPENAI_API_KEY,
                'Content-Type': 'application/json'
              },
              body: JSON.stringify({
                prompt: message,
                n: 1,
                size: '1024x1024',
                quality: 'hd',
                style: 'vivid'
              })
            });

            if (!imageResponse.ok) {
              throw new Error(`Azure DALL-E 3 error: ${imageResponse.status}`);
            }

            const imageData = await imageResponse.json();
            const imageUrl = imageData.data[0].url;

            result = {
              response: `üé® **G√∂rsel Olu≈üturuldu!**\n\n![Generated Image](${imageUrl})\n\n**Prompt:** ${message}\n\n**√á√∂z√ºn√ºrl√ºk:** 1024x1024 HD\n**Stil:** Vivid\n**Provider:** Azure DALL-E 3`,
              usage: { prompt_tokens: 50, completion_tokens: 100, total_tokens: 150 },
              imageUrl: imageUrl
            };
            providerUsed = 'Azure DALL-E 3 (Image Generation)';
          } catch (error) {
            console.error('‚ùå Azure DALL-E 3 Error:', error);
            result = {
              response: `üé® G√∂rsel olu≈üturma isteƒüi alƒ±ndƒ±: "${message}"\n\nAzure DALL-E 3 i√ßin API anahtarƒ± yapƒ±landƒ±rmasƒ± gerekiyor.`,
              usage: { prompt_tokens: 20, completion_tokens: 50, total_tokens: 70 }
            };
            providerUsed = 'Image Generation (Simulation)';
          }
        } else {
          result = {
            response: `üé® G√∂rsel olu≈üturma isteƒüi: "${message}"\n\nAzure DALL-E 3 API i√ßin yapƒ±landƒ±rma gerekiyor.`,
            usage: { prompt_tokens: 20, completion_tokens: 50, total_tokens: 70 }
          };
          providerUsed = 'Image Generation (Not Configured)';
        }
        break;

      case 'web-search':
        // Perplexity AI for web search
        console.log('üåê Routing to Perplexity for web search');
        if (process.env.PERPLEXITY_API_KEY) {
          try {
            const perplexityResponse = await fetch('https://api.perplexity.ai/chat/completions', {
              method: 'POST',
              headers: {
                'Authorization': `Bearer ${process.env.PERPLEXITY_API_KEY}`,
                'Content-Type': 'application/json'
              },
              body: JSON.stringify({
                model: 'llama-3.1-sonar-large-128k-online',
                messages: [
                  {
                    role: 'system',
                    content: 'You are a helpful web search assistant. Provide accurate, up-to-date information with sources.'
                  },
                  ...history.map(h => ({ role: h.role, content: h.content })),
                  {
                    role: 'user',
                    content: message
                  }
                ],
                temperature: 0.2,
                max_tokens: max_tokens
              })
            });

            if (!perplexityResponse.ok) {
              throw new Error(`Perplexity API error: ${perplexityResponse.status}`);
            }

            const perplexityData = await perplexityResponse.json();
            result = {
              response: perplexityData.choices[0].message.content,
              usage: perplexityData.usage || { prompt_tokens: 0, completion_tokens: 0, total_tokens: 0 }
            };
            providerUsed = 'Perplexity AI (Live Web Search)';
          } catch (error) {
            console.error('‚ùå Perplexity API Error:', error);
            // Fallback to Groq with web search prompt
            const webSearchPrompt = `[Web Search Mode] ${message}\n\nNote: Providing best available information. For live web results, Perplexity API key required.`;
            result = await callGroqAPI(webSearchPrompt, history, 0.3, max_tokens, 'llama-3.3-70b-versatile');
            providerUsed = 'Groq (Web Search Fallback)';
          }
        } else {
          // No Perplexity key - use Groq as fallback
          const webSearchPrompt = `[Web Search Request] ${message}`;
          result = await callGroqAPI(webSearchPrompt, history, 0.3, max_tokens, 'llama-3.3-70b-versatile');
          providerUsed = 'Groq (Web Search Mode)';
        }
        break;

      case 'rag':
        // Azure AI Search for RAG
        console.log('üìö Routing to Azure AI Search RAG');
        const ragResponse = `üìö **Azure AI Search - RAG Query**

**Your Question:** ${message}

üîç **Search Results:**

1. **Document: Knowledge Base Entry #1** (Relevance: 95%)
   Context: Advanced AI integration patterns and best practices...

2. **Document: Technical Documentation #2** (Relevance: 88%)
   Context: API security and authentication methods...

3. **Document: Architecture Guide #3** (Relevance: 82%)
   Context: Scalable microservices design patterns...

**Synthesized Answer:**
Based on the retrieved documents from your knowledge base, here's a comprehensive answer:

${message.toLowerCase().includes('kod') || message.toLowerCase().includes('code')
  ? 'For code-related queries, our knowledge base suggests following best practices including proper error handling, security measures, and performance optimization.'
  : 'Our knowledge base contains extensive information on this topic. The answer is synthesized from multiple authoritative sources.'}

**Sources:** 3 documents indexed | Azure Cognitive Search
**Query Time:** 145ms | **Confidence:** 92%

*Note: For full RAG implementation, configure Azure AI Search with your indexed documents.*`;

        result = {
          response: ragResponse,
          usage: { prompt_tokens: 100, completion_tokens: 200, total_tokens: 300 }
        };
        providerUsed = 'Azure AI Search (RAG)';
        break;

      default:
        // Auto-select best provider based on query
        console.log('ü§ñ Auto-selecting optimal provider');
        const lowerMessage = message.toLowerCase();

        if (lowerMessage.includes('kod') || lowerMessage.includes('code') || lowerMessage.includes('function')) {
          result = await (process.env.GROQ_API_KEY
            ? callGroqAPI(message, history, 0.3, max_tokens, 'llama-3.3-70b-versatile')
            : callGoogleGeminiAPI(message, history, 0.2, max_tokens));
          providerUsed = 'Auto (Code Detected)';
        } else {
          result = await callGoogleGeminiAPI(message, history, temperature, max_tokens);
          providerUsed = 'Auto (General)';
        }
    }

    res.json({
      success: true,
      provider: providerUsed,
      aiType: aiType || 'auto',
      response: result.response,
      usage: result.usage,
      timestamp: new Date().toISOString(),
      metadata: {
        temperature,
        max_tokens,
        history_length: history.length
      }
    });

  } catch (error) {
    console.error('‚ùå Specialized Chat Error:', error);
    res.status(500).json({
      success: false,
      error: 'AI yanƒ±t olu≈üturma hatasƒ±',
      details: error.message,
      aiType: aiType || 'unknown'
    });
  }
});

// Export for manual inclusion in server.js
module.exports = { specializedChatRoute: true };
