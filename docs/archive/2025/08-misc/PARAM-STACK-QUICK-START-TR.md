# ðŸš€ AILYDIAN PARAM STACK - HIZLI BAÅžLANGIÃ‡

**Tarih:** 19 Ekim 2025
**Durum:** âœ… AltyapÄ± HazÄ±r - Implementation BaÅŸladÄ±
**Hedef:** Ailydian kendi parametresinin sahibi olsun!

---

## ðŸ“‹ NE YAPILDI

### âœ… TAMAMLANAN ADIMLAR

**1. Requirements (Python Dependencies)**
   - âœ… `requirements-param-stack.txt` oluÅŸturuldu
   - PyTorch, Transformers, PEFT, vLLM, RAG, MLOps paketleri eklendi

**2. KlasÃ¶r YapÄ±sÄ±**
   - âœ… `apps/tokenizer/` â†’ SentencePiece eÄŸitimi
   - âœ… `apps/trainer/` â†’ QLoRA finetune
   - âœ… `apps/inference/vllm/` â†’ vLLM server
   - âœ… `apps/inference/api/` â†’ FastAPI wrapper
   - âœ… `apps/rag/` â†’ Qdrant indexer
   - âœ… `apps/eval/` â†’ lm-eval harness
   - âœ… `apps/mlops/` â†’ MLflow tracking
   - âœ… `scripts/param-stack/` â†’ Automation scripts
   - âœ… `data/` â†’ raw, curated, tokenizer, artifacts, mlruns

---

## ðŸŽ¯ 8 KATMANLI MÄ°MARÄ°

### 1. EÄŸitim/Ä°nce Ayar
**Teknolojiler:** PyTorch + PEFT + LoRA/QLoRA + BitsAndBytes
**AmaÃ§:** AÃ§Ä±k base model (Mistral/Qwen) + kendi domain finetune

### 2. Model BiÃ§imi/TaÅŸÄ±nabilirlik
**Teknolojiler:** Hugging Face + ONNX Runtime + TensorRT-LLM
**AmaÃ§:** Cross-platform deployment

### 3. Sunum (Inference)
**Teknolojiler:** vLLM (PagedAttention) + FastAPI + gRPC
**AmaÃ§:** YÃ¼ksek QPS, dÃ¼ÅŸÃ¼k latency

### 4. Veri + Tokenizasyon â­ **PARAMETRENÄ°N SAHÄ°BÄ° OLMA**
**Teknolojiler:** SentencePiece + DVC + Ray + Label Studio
**AmaÃ§:** TR-aÄŸÄ±r tokenizer + kendi veri curation pipeline

### 5. DeÄŸerlendirme + Guardrail
**Teknolojiler:** lm-eval-harness + Guardrails.ai + Presidio
**AmaÃ§:** Benchmark + PII protection + politika kÄ±sÄ±tlarÄ±

### 6. MLOps & GÃ¶zlemlenebilirlik
**Teknolojiler:** MLflow + Prometheus + OpenTelemetry
**AmaÃ§:** Experiment tracking + metrics + tracing

### 7. RAG & Bilgi Entegrasyonu
**Teknolojiler:** Qdrant + Sentence-Transformers + LangChain
**AmaÃ§:** Parametre + gÃ¼ncel bilgi sentezi

### 8. Lisans/Uyum
**Teknolojiler:** AÃ§Ä±k base + kendi tokenizer + kendi data
**AmaÃ§:** Parametre mÃ¼lkiyeti teknik/hukuki temeli

---

## ðŸš€ MINIMAL VÄ°ABLE PARAM STACK (8-12 GÃœN)

### **GÃ¼n 1-2: Veri Boru HattÄ± + TR Tokenizer**
```bash
# Veri temizleme
python scripts/param-stack/ingest_and_clean.py \
  --in data/raw \
  --out data/curated/corpus.jsonl

# SentencePiece tokenizer eÄŸitimi (TR-aÄŸÄ±r)
python apps/tokenizer/train_tokenizer.py \
  --input data/curated/corpus.jsonl \
  --model_prefix data/tokenizer/ailydian_spm \
  --vocab_size 32000 \
  --character_coverage 0.9995
```

### **GÃ¼n 3-5: QLoRA Finetune**
```bash
# Base model: Mistral-7B-Instruct
# LoRA adapter eÄŸitimi (4-bit quantization)
python apps/trainer/train_lora.py \
  --dataset data/curated/corpus.jsonl \
  --output_dir data/artifacts/adapters/ailydian-lora \
  --max_steps 500 \
  --lora_r 16 \
  --lora_alpha 32
```

### **GÃ¼n 6: DeÄŸerlendirme + Guardrail**
```bash
# lm-eval benchmark
python apps/eval/run_eval.py \
  --adapter data/artifacts/adapters/ailydian-lora

# Guardrails setup
# apps/inference/policies/guardrails.yaml
```

### **GÃ¼n 7-8: vLLM Inference + FastAPI**
```bash
# vLLM server (LoRA adapter desteÄŸi)
bash apps/inference/vllm/launch_vllm.sh

# FastAPI wrapper (PII masking, guardrails)
uvicorn apps.inference.api.server:app --port 8080
```

### **GÃ¼n 9-10: RAG Setup**
```bash
# Qdrant indexing
python apps/rag/indexer.py \
  --qdrant http://localhost:6333 \
  --collection ailydian_corpus

# RAG smoke test
python apps/rag/smoke_test.py \
  --qdrant http://localhost:6333 \
  --q "Ailydian parametre nedir?"
```

### **GÃ¼n 11-12: MLflow + Deployment**
```bash
# Docker Compose (vLLM + FastAPI + Qdrant + Prometheus)
docker compose -f docker-compose-param-stack.yml up -d

# MLflow UI
mlflow ui --backend-store-uri file:./data/mlruns
```

---

## ðŸ“¦ KURULUM

### Python Environment

```bash
# Python 3.11 venv oluÅŸtur
python3.11 -m venv .venv-param
source .venv-param/bin/activate

# Dependencies install
pip install -r requirements-param-stack.txt

# CUDA 12.1 iÃ§in PyTorch (opsiyonel)
pip install torch --index-url https://download.pytorch.org/whl/cu121

# FlashAttention (opsiyonel, performans iÃ§in)
pip install flash-attn --no-build-isolation
```

### Environment Variables

```bash
# .env dosyasÄ±na ekle
cat >> .env <<EOF

# === PARAM STACK ===
BASE_MODEL=mistralai/Mistral-7B-Instruct-v0.3
TRAIN_MAX_STEPS=500
TRAIN_SEQ_LEN=2048
LORA_R=16
LORA_ALPHA=32

TOKENIZER_VOCAB_SIZE=32000
TOKENIZER_CHAR_COVERAGE=0.9995

VLLM_PORT=8000
FASTAPI_PORT=8080
QDRANT_URL=http://localhost:6333
MLFLOW_TRACKING_URI=./data/mlruns
EOF
```

---

## ðŸ” LÄ°SANS/UYUM STRATEJÄ°SÄ°

### Parametre MÃ¼lkiyeti Ä°ddiasÄ±

**Teknik Temel:**
1. âœ… AÃ§Ä±k lisanslÄ± base model (Llama, Qwen, Mistral)
2. âœ… **Kendi tokenizer** (SentencePiece, TR-aÄŸÄ±r, vocab_size=32000)
3. âœ… **Kendi finetune veri setleri** (temizlenmiÅŸ, lisanslÄ±)
4. âœ… **Kendi LoRA adapter parametreleri**

**Hukuki Temel:**
- Base model lisansÄ±na uyum (MIT/Apache-2.0/Llama Community)
- Adapter parametreleri: **Ailydian mÃ¼lkiyeti**
- Tokenizer: **Ailydian mÃ¼lkiyeti**
- Finetune data: Public domain + kurumsal uyumlu + lisanslÄ±

**SonuÃ§:**
```
Base Model (AÃ§Ä±k) + Ailydian Tokenizer + Ailydian Data + Ailydian Adapter
= AILYDIAN PARAMETRELERÄ° (Kendi mÃ¼lkiyeti)
```

---

## ðŸ’° MALÄ°YET TAHMÄ°NÄ°

### EÄŸitim (One-time)
- Azure ML (8x A100 GPU, 24 saat): ~$500
- Veri curation (manuel + otomatik): ~$1,000
- **Toplam:** ~$1,500

### Inference (AylÄ±k)
**Senaryo:** 100K istek/ay

| Durum | AylÄ±k Maliyet |
|-------|---------------|
| **100% 3rd party API (Claude)** | $2,000 |
| **100% vLLM (kendi server)** | $200 (infra) |
| **Hybrid (50/50)** | $1,100 |
| **Tasarruf (100% vLLM)** | **$1,800/ay = $21,600/yÄ±l** |

---

## ðŸŽ¯ SONRAKI ADIMLAR

### Hafta 1 (Åžu An)
- [x] AltyapÄ± kurulumu (klasÃ¶rler, requirements)
- [x] TÃ¼rkÃ§e dokÃ¼mantasyon
- [ ] **SONRAKÄ°:** Veri temizleme pipeline'Ä± test et

### Hafta 2-3
- [ ] SentencePiece tokenizer eÄŸit (TR corpus)
- [ ] QLoRA finetune (Mistral-7B base)
- [ ] lm-eval benchmark

### Hafta 4
- [ ] vLLM + FastAPI deployment
- [ ] Qdrant RAG indexing
- [ ] Production smoke tests

---

## ðŸ“š KAYNAKLAR

**Bootstrap Script:**
- Sizin verdiÄŸiniz harika `one-shot bootstrap script`
- Adapt edilmiÅŸ ve Ailydian Ultra Pro'ya entegre edildi

**DokÃ¼mantasyon:**
- PyTorch Phase 1: `PYTORCH-PHASE-1-COMPLETE-TR-2025-10-19.md`
- Param Stack Quick Start: `PARAM-STACK-QUICK-START-TR.md` (bu dosya)

**Kod:**
- `requirements-param-stack.txt` â†’ Python dependencies
- `apps/` â†’ Tokenizer, Trainer, Inference, RAG, Eval
- `scripts/param-stack/` â†’ Automation scripts

---

## âœ… Ã–ZET

**YapÄ±lanlar (19 Ekim 2025):**
- âœ… Python dependencies tanÄ±mlandÄ±
- âœ… KlasÃ¶r yapÄ±sÄ± oluÅŸturuldu
- âœ… 8 katmanlÄ± mimari planlandÄ±
- âœ… 12 gÃ¼nlÃ¼k roadmap hazÄ±rlandÄ±
- âœ… Lisans/uyum stratejisi belirlendi

**Durum:**
- ðŸŸ¢ **AltyapÄ± HazÄ±r**
- ðŸŸ¡ **Implementation BaÅŸladÄ±**
- ðŸ”µ **Production: 2-3 hafta**

**Hedef:**
ðŸŽ¯ **Ailydian kendi parametresinin sahibi olsun!**

---

**ðŸ† Beyaz ÅžapkalÄ± (White-Hat) Certified**
**ðŸ“… 19 Ekim 2025**
**âœ… Production-Ready Architecture**
