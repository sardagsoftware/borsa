// ============================================
// üëÅÔ∏è LYDIAN IQ - VISION API
// Multimodal AI: Image Analysis + Vision-Language Models
// ============================================

const OpenAI = require('openai');
const Anthropic = require('@anthropic-ai/sdk');

// Import middlewares (Beyaz ≈ûapkalƒ± G√ºvenlik)
const { rateLimitMiddleware } = require('../_middleware/rate-limiter');
const { inputValidationMiddleware } = require('../_middleware/input-validator');
const { csrfMiddleware } = require('../_middleware/csrf-protection');

// Import Redis cache (optional - graceful degradation)
let redisCache = null;
try {
    const redisCacheModule = require('../../lib/cache/redis-cache');
    redisCache = redisCacheModule.redisCache;
    console.log('‚úÖ Redis cache module loaded');
} catch (error) {
    console.warn('‚ö†Ô∏è Redis cache module failed to load:', error.message);
    redisCache = {
        enabled: false,
        get: async () => null,
        set: async () => false
    };
}

// Environment check
const IS_PRODUCTION = process.env.VERCEL_ENV === 'production' || process.env.NODE_ENV === 'production';

// Initialize AI providers
const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY
});

const anthropic = new Anthropic({
    apiKey: process.env.ANTHROPIC_API_KEY
});

// Generic error response helper (Beyaz ≈ûapkalƒ±)
function getGenericError(userMessage = 'Bir hata olu≈ütu. L√ºtfen tekrar deneyin.') {
    return {
        success: false,
        error: userMessage
    };
}

/**
 * Vision API Handler
 * Supports: GPT-4 Vision, Claude 3 Vision
 * Input: Base64 image + text prompt
 */
async function handleVisionRequest(req, res) {
    try {
        const { image, prompt, provider = 'gpt4-vision', language = 'tr-TR' } = req.body;

        // Validation
        if (!image || !prompt) {
            console.warn('[Vision API] Missing image or prompt');
            return res.status(400).json(getGenericError('Ge√ßersiz istek'));
        }

        // Validate base64 image
        if (!image.startsWith('data:image/')) {
            console.warn('[Vision API] Invalid image format');
            return res.status(400).json(getGenericError('Ge√ßersiz resim formatƒ±'));
        }

        // Check prompt length
        if (prompt.length < 5 || prompt.length > 5000) {
            console.warn('[Vision API] Invalid prompt length:', prompt.length);
            return res.status(400).json(getGenericError('Ge√ßersiz istek'));
        }

        // ‚ö° Try cache first (hash of image + prompt)
        const crypto = require('crypto');
        const cacheKey = crypto.createHash('md5')
            .update(image.substring(0, 100) + prompt) // Use first 100 chars of base64
            .digest('hex');

        const cachedResult = await redisCache.get(cacheKey, 'vision', language);
        if (cachedResult) {
            console.log('‚ö° Returning cached vision response');
            return res.status(200).json(cachedResult);
        }

        // Process with AI provider
        const startTime = Date.now();
        let result;

        switch (provider) {
            case 'gpt4-vision':
                result = await analyzeWithGPT4Vision(image, prompt, language);
                break;

            case 'claude-vision':
                result = await analyzeWithClaudeVision(image, prompt, language);
                break;

            default:
                // Default to GPT-4 Vision
                result = await analyzeWithGPT4Vision(image, prompt, language);
                break;
        }

        const responseTime = ((Date.now() - startTime) / 1000).toFixed(2);

        // Build response
        const response = {
            success: true,
            analysis: result.analysis,
            detectedObjects: result.detectedObjects || [],
            ocrText: result.ocrText || null,
            confidence: result.confidence || 0.95,
            metadata: {
                responseTime: responseTime,
                model: result.model,
                provider: provider,
                language: language,
                imageSize: image.length,
                mode: IS_PRODUCTION ? 'production' : 'development'
            }
        };

        // ‚ö° Cache the result
        await redisCache.set(cacheKey, 'vision', language, response, 3600); // 1 hour TTL

        return res.status(200).json(response);

    } catch (error) {
        console.error('[Vision API] Error:', error);

        // Return generic error to client (Beyaz ≈ûapkalƒ±)
        return res.status(500).json(getGenericError('G√∂r√ºnt√º analizi ba≈üarƒ±sƒ±z. L√ºtfen tekrar deneyin.'));
    }
}

/**
 * Analyze image with GPT-4 Vision
 */
async function analyzeWithGPT4Vision(imageBase64, prompt, language) {
    try {
        const systemPrompt = language.startsWith('tr')
            ? 'Sen g√∂rsel analiz yapan geli≈ümi≈ü bir AI asistanƒ±sƒ±n. G√∂rselleri detaylƒ± analiz eder, nesneleri tespit eder ve T√ºrk√ße a√ßƒ±klamalar yaparsƒ±n.'
            : 'You are an advanced AI assistant that analyzes images in detail, detects objects, and provides comprehensive explanations.';

        const response = await openai.chat.completions.create({
            model: 'gpt-4-vision-preview',
            messages: [
                {
                    role: 'system',
                    content: systemPrompt
                },
                {
                    role: 'user',
                    content: [
                        {
                            type: 'text',
                            text: prompt
                        },
                        {
                            type: 'image_url',
                            image_url: {
                                url: imageBase64,
                                detail: 'high' // High resolution analysis
                            }
                        }
                    ]
                }
            ],
            max_tokens: 1000,
            temperature: 0.7
        });

        const analysis = response.choices[0].message.content;

        // Extract objects from analysis (simple keyword extraction)
        const detectedObjects = extractObjects(analysis);

        return {
            analysis: analysis,
            detectedObjects: detectedObjects,
            ocrText: null, // GPT-4 Vision can read text, extract if needed
            confidence: 0.95,
            model: 'GPT-4 Vision'
        };

    } catch (error) {
        console.error('[GPT-4 Vision] Error:', error.message);
        throw error;
    }
}

/**
 * Analyze image with Claude 3 Vision
 */
async function analyzeWithClaudeVision(imageBase64, prompt, language) {
    try {
        const systemPrompt = language.startsWith('tr')
            ? 'Sen g√∂rsel analiz yapan geli≈ümi≈ü bir AI asistanƒ±sƒ±n. G√∂rselleri detaylƒ± analiz eder ve T√ºrk√ße a√ßƒ±klamalar yaparsƒ±n.'
            : 'You are an advanced AI assistant that analyzes images in detail and provides comprehensive explanations.';

        // Claude expects base64 without data:image/jpeg;base64, prefix
        const base64Data = imageBase64.split(',')[1];
        const imageType = imageBase64.split(';')[0].split('/')[1]; // jpeg, png, etc.

        const response = await anthropic.messages.create({
            model: 'claude-3-5-sonnet-20241022',
            max_tokens: 1000,
            system: systemPrompt,
            messages: [
                {
                    role: 'user',
                    content: [
                        {
                            type: 'image',
                            source: {
                                type: 'base64',
                                media_type: `image/${imageType}`,
                                data: base64Data
                            }
                        },
                        {
                            type: 'text',
                            text: prompt
                        }
                    ]
                }
            ]
        });

        const analysis = response.content[0].text;

        // Extract objects from analysis
        const detectedObjects = extractObjects(analysis);

        return {
            analysis: analysis,
            detectedObjects: detectedObjects,
            ocrText: null,
            confidence: 0.96,
            model: 'Claude 3.5 Sonnet'
        };

    } catch (error) {
        console.error('[Claude Vision] Error:', error.message);
        throw error;
    }
}

/**
 * Extract detected objects from AI analysis text
 * Simple keyword extraction (can be improved with NER)
 */
function extractObjects(analysisText) {
    const objectKeywords = [
        'person', 'people', 'man', 'woman', 'child', 'face',
        'car', 'vehicle', 'truck', 'bus', 'motorcycle',
        'dog', 'cat', 'animal', 'bird',
        'building', 'house', 'tree', 'flower', 'plant',
        'table', 'chair', 'furniture',
        'computer', 'phone', 'laptop', 'screen',
        'book', 'paper', 'text', 'document',
        'food', 'drink', 'plate', 'cup'
    ];

    const turkishKeywords = [
        'insan', 'ki≈üi', 'adam', 'kadƒ±n', '√ßocuk', 'y√ºz',
        'araba', 'ara√ß', 'kamyon', 'otob√ºs', 'motosiklet',
        'k√∂pek', 'kedi', 'hayvan', 'ku≈ü',
        'bina', 'ev', 'aƒüa√ß', '√ßi√ßek', 'bitki',
        'masa', 'sandalye', 'mobilya',
        'bilgisayar', 'telefon', 'laptop', 'ekran',
        'kitap', 'kaƒüƒ±t', 'metin', 'belge',
        'yemek', 'i√ßecek', 'tabak', 'bardak'
    ];

    const allKeywords = [...objectKeywords, ...turkishKeywords];
    const detectedObjects = [];
    const lowerAnalysis = analysisText.toLowerCase();

    for (const keyword of allKeywords) {
        if (lowerAnalysis.includes(keyword)) {
            if (!detectedObjects.includes(keyword)) {
                detectedObjects.push(keyword);
            }
        }
    }

    return detectedObjects.slice(0, 10); // Return top 10 objects
}

/**
 * Main API Handler
 */
module.exports = async (req, res) => {
    // CORS Headers
    const allowedOrigins = [
        'https://www.ailydian.com',
        'https://ailydian.com',
        'https://ailydian-ultra-pro.vercel.app',
        'http://localhost:3000',
        'http://localhost:3100'
    ];

    const origin = req.headers.origin;
    if (allowedOrigins.includes(origin)) {
        res.setHeader('Access-Control-Allow-Origin', origin);
    }

    res.setHeader('Access-Control-Allow-Methods', 'POST, OPTIONS');
    res.setHeader('Access-Control-Allow-Headers', 'Content-Type, x-csrf-token');
    res.setHeader('Access-Control-Allow-Credentials', 'true');

    if (req.method === 'OPTIONS') {
        return res.status(200).end();
    }

    if (req.method !== 'POST') {
        return res.status(405).json(getGenericError('Method not allowed'));
    }

    // üîí Apply security middlewares
    return new Promise((resolve) => {
        rateLimitMiddleware(req, res, () => {
            csrfMiddleware(req, res, () => {
                inputValidationMiddleware(req, res, async () => {
                    try {
                        await handleVisionRequest(req, res);
                        resolve();
                    } catch (error) {
                        console.error('[Handler Error]', error);
                        res.status(500).json(getGenericError('Sunucu hatasƒ±. L√ºtfen daha sonra tekrar deneyin.'));
                        resolve();
                    }
                });
            });
        });
    });
};
