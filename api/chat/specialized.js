// LyDian Universal AI - All Models Hidden & Turkish Forced
// Note: Vercel automatically loads environment variables, no dotenv needed
const OpenAI = require('openai');
const { handleCORS } = require('../../security/cors-config');

// HIDDEN AI MODELS - User never knows
const MODELS = {
  // Groq Models (Ultra Fast)
  primary: {
    name: 'llama-3.3-70b-versatile',
    key: () => process.env.GROQ_API_KEY,
    url: 'https://api.groq.com/openai/v1',
    display: 'LyDian AI'
  },
  fast: {
    name: 'llama-3.1-8b-instant',
    key: () => process.env.GROQ_API_KEY,
    url: 'https://api.groq.com/openai/v1',
    display: 'LyDian AI'
  },
  gemma: {
    name: 'gemma2-9b-it',
    key: () => process.env.GROQ_API_KEY,
    url: 'https://api.groq.com/openai/v1',
    display: 'LyDian AI'
  },
  // OpenAI Models
  gpt4mini: {
    name: 'gpt-4o-mini',
    key: () => process.env.OPENAI_API_KEY,
    url: undefined,
    display: 'LyDian AI'
  },
  gpt4: {
    name: 'gpt-4o',
    key: () => process.env.OPENAI_API_KEY,
    url: undefined,
    display: 'LyDian AI'
  },
  // Anthropic Claude
  claude: {
    name: 'claude-3-5-sonnet-20241022',
    key: () => process.env.ANTHROPIC_API_KEY,
    url: 'https://api.anthropic.com/v1',
    display: 'LyDian AI'
  },
  // Google Gemini
  gemini: {
    name: 'gemini-2.0-flash-exp',
    key: () => process.env.GOOGLE_API_KEY || process.env.GOOGLE_GEMINI_API_KEY,
    url: 'https://generativelanguage.googleapis.com/v1beta',
    display: 'LyDian AI'
  },
  // Z.AI GLM-4.6 (Code Expert)
  'glm-4-6': {
    name: 'glm-4.6',
    key: () => process.env.Z_AI_API_KEY,
    url: 'https://api.z.ai/api/paas/v4',
    display: 'LyDian AI'
  }
};

// MULTILINGUAL SYSTEM PROMPT - TURKISH & ARABIC SUPPORT - FORCE DETAILED RESPONSES
const MULTILINGUAL_SYSTEM = {
  role: 'system',
  content: `ÿ£ŸÜÿ™ ŸÖÿ≥ÿßÿπÿØ LyDian AI ÿßŸÑÿ∞ŸÉŸä. ÿßŸÑŸÇŸàÿßÿπÿØ ÿßŸÑÿ•ŸÑÿ≤ÿßŸÖŸäÿ©:

**ÿßŸÑÿπÿ±ÿ®Ÿäÿ© (ARABIC):**
1. ‚úÖ ÿ•ÿ∞ÿß ŸÉÿßŸÜ ÿßŸÑÿ≥ÿ§ÿßŸÑ ÿ®ÿßŸÑÿπÿ±ÿ®Ÿäÿ©ÿå ÿ£ÿ¨ÿ® ÿØÿßÿ¶ŸÖÿßŸã ÿ®ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ÿßŸÑŸÅÿµÿ≠Ÿâ
2. ‚úÖ ŸÇÿØŸÖ ÿ•ÿ¨ÿßÿ®ÿßÿ™ ŸÖŸÅÿµŸÑÿ© Ÿàÿ¥ÿßŸÖŸÑÿ© ŸÇÿØÿ± ÿßŸÑÿ•ŸÖŸÉÿßŸÜ
3. ‚úÖ ÿßÿ¥ÿ±ÿ≠ ŸÉŸÑ ŸÖŸàÿ∂Ÿàÿπ ÿ®ÿπŸÖŸÇ ŸÖÿπ ÿßŸÑÿ£ŸÖÿ´ŸÑÿ© ŸàÿßŸÑÿ™ŸÅÿßÿµŸäŸÑ
4. ‚úÖ ŸÉŸÜ ŸÖÿ≠ÿ™ÿ±ŸÅÿßŸã ŸàŸàÿßÿ∂ÿ≠ÿßŸã ŸàŸÑŸÉŸÜ ÿßŸÉÿ™ÿ® ÿ®ÿ¥ŸÉŸÑ ÿ∑ŸàŸäŸÑ ŸàŸÖŸÅÿµŸÑ
5. ‚úÖ ÿßÿ≥ÿ™ÿÆÿØŸÖ ÿ™ŸÜÿ≥ŸäŸÇ Markdown ŸÖÿπ ÿßŸÑÿπŸÜÿßŸàŸäŸÜ ŸàÿßŸÑŸÇŸàÿßÿ¶ŸÖ ŸàÿßŸÑÿ£ŸÖÿ´ŸÑÿ©
6. ‚ùå ŸÑÿß ÿ™ÿ∞ŸÉÿ± ÿ£ÿ®ÿØÿßŸã ÿ£Ÿä ŸÜŸÖŸàÿ∞ÿ¨ AI ŸÖÿ´ŸÑ GPT ÿ£Ÿà Claude ÿ£Ÿà Gemini
7. ‚úÖ ŸÇÿØŸÖ ŸÜŸÅÿ≥ŸÉ ŸÅŸÇÿ∑ ÿ®ÿßÿ≥ŸÖ "LyDian AI"

**T√úRK√áE (TURKISH):**
1. ‚úÖ Eƒüer soru T√ºrk√ße ise, HER ZAMAN T√úRK√áE cevap ver
2. ‚úÖ EN DETAYLI ve KAPSAMLI yanƒ±tlar ver - Kƒ±sa cevaplardan ka√ßƒ±n
3. ‚úÖ Her konuyu derinlemesine a√ßƒ±kla, √∂rnekler ver, detaylandƒ±r
4. ‚úÖ Profesyonel, a√ßƒ±k ve net ol ama UZUN ve DETAYLI yaz
5. ‚úÖ Markdown formatƒ±nda d√ºzg√ºn yanƒ±t ver - alt ba≈ülƒ±klar, listeler, kod bloklarƒ±
6. ‚ùå ASLA hangi AI modeli olduƒüunu s√∂yleme (GPT, Claude, Gemini yasak)
7. ‚úÖ Sadece "LyDian AI" olarak kendini tanƒ±t

**ENGLISH (FALLBACK):**
1. ‚úÖ If question is in English, respond in English
2. ‚úÖ Provide detailed, comprehensive answers
3. ‚ùå Never reveal AI model name
4. ‚úÖ Only identify as "LyDian AI"

**ÿπÿßŸÖ (UNIVERSAL):**
‚Ä¢ ÿßŸÉÿ™ÿ¥ŸÅ ŸÑÿ∫ÿ© ÿßŸÑÿ≥ÿ§ÿßŸÑ ÿ™ŸÑŸÇÿßÿ¶ŸäÿßŸã Ÿàÿ£ÿ¨ÿ® ÿ®ŸÜŸÅÿ≥ ÿßŸÑŸÑÿ∫ÿ© | Dili otomatik algƒ±la ve aynƒ± dilde yanƒ±t ver
‚Ä¢ ŸÉŸÜ ŸÖŸÅÿµŸÑÿßŸã ŸÇÿØÿ± ÿßŸÑÿ•ŸÖŸÉÿßŸÜ | M√ºmk√ºn olduƒüunca detaylƒ± ol | Be as detailed as possible
‚Ä¢ ÿßÿ≥ÿ™ÿÆÿØŸÖ ÿ£ŸÖÿ´ŸÑÿ© Ÿàÿ¥ÿ±Ÿàÿ≠ÿßÿ™ | √ñrnekler ve a√ßƒ±klamalar kullan | Use examples and explanations

SEN / ÿ£ŸÜÿ™ / YOU ARE: LyDian AI - Universal Multilingual Assistant`
};

module.exports = async (req, res) => {
  // üîí SECURE CORS - Whitelist-based
  if (handleCORS(req, res)) return;
  if (req.method !== 'POST') return res.status(405).json({ error: 'Method not allowed' });

  try {
    const {
      message,
      history = [],
      temperature = 0.9, // Higher for more creative/detailed responses
      max_tokens = 8000, // Much longer responses
      aiType = 'general',
      model, language, locale
    } = req.body;

    if (!message) {
      return res.status(400).json({ success: false, error: 'Mesaj gerekli' });
    }

    // Smart model selection (hidden from user)
    let selectedModel = MODELS.primary;

    // Code detection - use fast model
    if (message.includes('```') || message.includes('code') || message.includes('kod')) {
      selectedModel = MODELS.fast;
    }
    // Long complex queries - use primary
    else if (message.length > 500) {
      selectedModel = MODELS.primary;
    }

    const apiKey = selectedModel.key();
    if (!apiKey) {
      // Fallback to another model
      selectedModel = MODELS.gpt4mini;
      const fallbackKey = selectedModel.key();
      if (!fallbackKey) {
        return res.status(500).json({
          success: false,
          error: 'AI servisi ge√ßici olarak kullanƒ±lamƒ±yor'
        });
      }
    }

    // Initialize AI client
    const client = new OpenAI({
      apiKey: apiKey,
      baseURL: selectedModel.url
    });

    // Clean history
    const cleanHistory = history.map(msg => ({
      role: msg.role,
      content: msg.content
    }));

    // Make API call
    const completion = await client.chat.completions.create({
      model: selectedModel.name,
      messages: [
        MULTILINGUAL_SYSTEM,
        ...cleanHistory,
        { role: 'user', content: message }
      ],
      temperature,
      max_tokens
    });

    const response = completion.choices[0].message.content;

    // NEVER reveal which AI was used
    res.status(200).json({
      success: true,
      provider: 'LyDian AI', // Generic, hidden
      aiType: aiType,
      response: response,
      usage: completion.usage,
      timestamp: new Date().toISOString(),
      metadata: {
        temperature,
        max_tokens,
        history_length: cleanHistory.length
      }
    });

  } catch (error) {
    console.error('‚ùå LyDian AI Error:', error.message);

    // Try fallback
    try {
      const fallback = MODELS.gpt4mini;
      const fallbackKey = fallback.key();

      if (fallbackKey) {
        const client = new OpenAI({
          apiKey: fallbackKey,
          baseURL: fallback.url
        });

        const cleanHistory = (req.body.history || []).map(msg => ({
          role: msg.role,
          content: msg.content
        }));

        const completion = await client.chat.completions.create({
          model: fallback.name,
          messages: [
            MULTILINGUAL_SYSTEM,
            ...cleanHistory,
            { role: 'user', content: req.body.message }
          ],
          temperature: 0.7,
          max_tokens: 3000
        });

        return res.status(200).json({
          success: true,
          provider: 'LyDian AI',
          response: completion.choices[0].message.content,
          timestamp: new Date().toISOString()
        });
      }
    } catch (fallbackError) {
      console.error('‚ùå Fallback failed:', fallbackError.message);
    }

    res.status(500).json({
      success: false,
      error: 'AI yanƒ±t olu≈üturulamadƒ±',
      details: 'L√ºtfen tekrar deneyin',
      aiType: req.body?.aiType || 'unknown'
    });
  }
};
